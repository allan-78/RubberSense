{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Disease Classification and Spot Counting with YOLOv8\n",
    "\n",
    "This notebook trains a YOLOv8 Classification model to distinguish between Healthy and Diseased leaves. Additionally, for leaves classified as 'Diseased', it uses image processing to estimate the number of disease spots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics YOLOv8\n",
    "!pip install ultralytics\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset\n",
    "# Assuming the file is at /content/drive/MyDrive/Final-Leaf-Datasets.zip\n",
    "zip_path = '/content/drive/MyDrive/Final-Leaf-Datasets.zip'\n",
    "extract_path = '/content/temp_dataset'\n",
    "\n",
    "if os.path.exists(zip_path):\n",
    "    !unzip -q \"{zip_path}\" -d \"{extract_path}\"\n",
    "    print(\"Dataset extracted successfully.\")\n",
    "else:\n",
    "    print(f\"File not found at {zip_path}. Please check the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We need to reorganize the dataset into the standard YOLO classification structure:\n",
    "```\n",
    "datasets/leaf_dataset/\n",
    "  train/\n",
    "    healthy/\n",
    "    diseased/\n",
    "  val/\n",
    "    healthy/\n",
    "    diseased/\n",
    "```\n",
    "The script below recursively finds all images in your extracted `Healthy` and `Diseased` folders and splits them into train/val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "output_dir = '/content/datasets/leaf_dataset'\n",
    "train_ratio = 0.8  # 80% training, 20% validation\n",
    "\n",
    "# Clear existing dataset if any\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    for category in ['healthy', 'diseased']:\n",
    "        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n",
    "\n",
    "def get_image_files(directory):\n",
    "    image_files = []\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1].lower() in valid_extensions:\n",
    "                image_files.append(os.path.join(root, file))\n",
    "    return image_files\n",
    "\n",
    "# Locate the source directories\n",
    "# We look for 'Healthy' and 'Diseased' folders in the extracted path\n",
    "source_healthy = None\n",
    "source_diseased = None\n",
    "\n",
    "for root, dirs, files in os.walk(extract_path):\n",
    "    for d in dirs:\n",
    "        if d.lower() == 'healthy':\n",
    "            source_healthy = os.path.join(root, d)\n",
    "        elif d.lower() == 'diseased':\n",
    "            source_diseased = os.path.join(root, d)\n",
    "\n",
    "if not source_healthy or not source_diseased:\n",
    "    print(\"Error: Could not find 'Healthy' and 'Diseased' folders. Please check the zip structure.\")\n",
    "    # Attempt to print structure to help debug if this happens\n",
    "    print(\"Found directories:\")\n",
    "    for root, dirs, files in os.walk(extract_path):\n",
    "        for d in dirs:\n",
    "            print(os.path.join(root, d))\n",
    "else:\n",
    "    print(f\"Found Healthy folder at: {source_healthy}\")\n",
    "    print(f\"Found Diseased folder at: {source_diseased}\")\n",
    "\n",
    "    # Process Healthy Images\n",
    "    healthy_images = get_image_files(source_healthy)\n",
    "    random.shuffle(healthy_images)\n",
    "    split_idx = int(len(healthy_images) * train_ratio)\n",
    "    \n",
    "    for i, img_path in enumerate(healthy_images):\n",
    "        split = 'train' if i < split_idx else 'val'\n",
    "        shutil.copy(img_path, os.path.join(output_dir, split, 'healthy', os.path.basename(img_path)))\n",
    "    \n",
    "    print(f\"Processed {len(healthy_images)} healthy images.\")\n",
    "\n",
    "    # Process Diseased Images\n",
    "    diseased_images = get_image_files(source_diseased)\n",
    "    random.shuffle(diseased_images)\n",
    "    split_idx = int(len(diseased_images) * train_ratio)\n",
    "    \n",
    "    for i, img_path in enumerate(diseased_images):\n",
    "        split = 'train' if i < split_idx else 'val'\n",
    "        shutil.copy(img_path, os.path.join(output_dir, split, 'diseased', os.path.basename(img_path)))\n",
    "        \n",
    "    print(f\"Processed {len(diseased_images)} diseased images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train YOLOv8 Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained YOLOv8n-cls model\n",
    "model = YOLO('yolov8n-cls.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=output_dir, \n",
    "    epochs=20, \n",
    "    imgsz=224, \n",
    "    name='leaf_disease_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot Counting Logic\n",
    "Since the dataset does not have bounding box labels for spots, we cannot train an object detector to count them directly. Instead, we use Computer Vision (OpenCV) to detect spots on leaves classified as 'diseased'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spots(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return 0, None\n",
    "    \n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define range for brown/dark spots (typical for leaf disease)\n",
    "    # Note: These values might need tuning based on your specific leaf images\n",
    "    lower_brown = np.array([0, 0, 0])\n",
    "    upper_brown = np.array([180, 255, 100]) # Low brightness/value captures dark spots\n",
    "    \n",
    "    # Or use edge detection/blob detection\n",
    "    # Let's try a simple adaptive threshold approach which is more robust\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Invert so dark spots become bright\n",
    "    gray_inv = cv2.bitwise_not(gray)\n",
    "    \n",
    "    # Threshold to isolate the spots\n",
    "    # We assume spots are significantly darker than the leaf\n",
    "    _, thresh = cv2.threshold(gray_inv, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter small noise\n",
    "    min_spot_area = 10\n",
    "    spot_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_spot_area]\n",
    "    \n",
    "    # Draw contours on image for visualization\n",
    "    vis_img = img.copy()\n",
    "    cv2.drawContours(vis_img, spot_contours, -1, (0, 0, 255), 2)\n",
    "    \n",
    "    return len(spot_contours), vis_img\n",
    "\n",
    "def predict_and_count(image_path, model):\n",
    "    # 1. Run Classification\n",
    "    results = model(image_path)\n",
    "    probs = results[0].probs\n",
    "    top1_index = probs.top1\n",
    "    class_name = results[0].names[top1_index]\n",
    "    \n",
    "    print(f\"Prediction: {class_name.upper()}\")\n",
    "    \n",
    "    # 2. If Diseased, Count Spots\n",
    "    if class_name == 'diseased':\n",
    "        count, vis_img = count_spots(image_path)\n",
    "        print(f\"Estimated Spot Count: {count}\")\n",
    "        cv2_imshow(vis_img)\n",
    "    else:\n",
    "        print(\"Leaf is Healthy. No spots to count.\")\n",
    "        img = cv2.imread(image_path)\n",
    "        cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random validation image\n",
    "import glob\n",
    "val_diseased = glob.glob(f\"{output_dir}/val/diseased/*.jpg\")\n",
    "if val_diseased:\n",
    "    test_image = random.choice(val_diseased)\n",
    "    predict_and_count(test_image, model)\n",
    "else:\n",
    "    print(\"No validation images found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}